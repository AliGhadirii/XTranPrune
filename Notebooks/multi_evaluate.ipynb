{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Use multiple rounds to get a more robust results'''\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, balanced_accuracy_score, roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(df):\n",
    "    \"\"\"\n",
    "    calculate average accuracy, accuracy per skin type, PQD, DPM, EOM, EOpp0, EOpp1, EOdd, and NAR.\n",
    "    Skin type in the input df should be in the range of [0,5].\n",
    "    input val results csv path, type_indices: a list\n",
    "    output a dic, 'acc_avg': value, 'acc_per_type': array[x,x,x], 'PQD', 'DPM', 'EOM'\n",
    "    \"\"\"\n",
    "    is_binaryCLF = len(df[\"label\"].unique()) == 2\n",
    "\n",
    "    type_indices = sorted(list(df[\"fitzpatrick\"].unique()))\n",
    "    type_indices_binary = sorted(list(df[\"fitzpatrick_binary\"].unique()))\n",
    "\n",
    "    labels_array = np.zeros((6, len(df[\"label\"].unique())))\n",
    "    correct_array = np.zeros((6, len(df[\"label\"].unique())))\n",
    "    predictions_array = np.zeros((6, len(df[\"label\"].unique())))\n",
    "    prob_array = [[] for i in range(len(df[\"fitzpatrick\"].unique()))]\n",
    "    label_array_per_fitz = [[] for i in range(len(df[\"fitzpatrick\"].unique()))]\n",
    "\n",
    "    labels_array_binary = np.zeros((2, len(df[\"label\"].unique())))\n",
    "    correct_array_binary = np.zeros((2, len(df[\"label\"].unique())))\n",
    "    predictions_array_binary = np.zeros((2, len(df[\"label\"].unique())))\n",
    "\n",
    "    positive_list = []  # get positive probability for binary classification\n",
    "    labels_ft0 = []\n",
    "    labels_ft1 = []\n",
    "    predictions_ft0 = []\n",
    "    predictions_ft1 = []\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        prediction = df.iloc[i][\"prediction\"]\n",
    "        label = df.iloc[i][\"label\"]\n",
    "        type = df.iloc[i][\"fitzpatrick\"]\n",
    "        type_binary = df.iloc[i][\"fitzpatrick_binary\"]\n",
    "\n",
    "        labels_array[int(type), int(label)] += 1\n",
    "        predictions_array[int(type), int(prediction)] += 1\n",
    "        if prediction == label:\n",
    "            correct_array[int(type), int(label)] += 1\n",
    "\n",
    "        labels_array_binary[int(type_binary), int(label)] += 1\n",
    "        predictions_array_binary[int(type_binary), int(prediction)] += 1\n",
    "        if prediction == label:\n",
    "            correct_array_binary[int(type_binary), int(label)] += 1\n",
    "\n",
    "        if is_binaryCLF:\n",
    "            prob_array[int(type)].append(df.iloc[i][\"prediction_probability\"])\n",
    "            label_array_per_fitz[int(type)].append(label)\n",
    "            if prediction == 0:\n",
    "                positive_list.append(1.0 - df.iloc[i][\"prediction_probability\"])\n",
    "            else:\n",
    "                positive_list.append(df.iloc[i][\"prediction_probability\"])\n",
    "\n",
    "        if type_binary == 0:\n",
    "            labels_ft0.append(label)\n",
    "            predictions_ft0.append(prediction)\n",
    "        else:\n",
    "            labels_ft1.append(label)\n",
    "            predictions_ft1.append(prediction)\n",
    "\n",
    "    correct_array = correct_array[type_indices]\n",
    "    labels_array = labels_array[type_indices]\n",
    "    predictions_array = predictions_array[type_indices]\n",
    "\n",
    "    # avg acc, acc per type\n",
    "    correct_array_sumc, labels_array_sumc = np.sum(correct_array, axis=1), np.sum(\n",
    "        labels_array, axis=1\n",
    "    )  # sum skin conditions\n",
    "    acc_array = (correct_array_sumc / labels_array_sumc) * 100\n",
    "    avg_acc = (np.sum(correct_array) / np.sum(labels_array)) * 100\n",
    "\n",
    "    # f1_score, f1-score per type\n",
    "    F1 = f1_score(df[\"label\"], df[\"prediction\"], average=\"weighted\") * 100\n",
    "\n",
    "    F1_array = []\n",
    "    for i in range(6):\n",
    "        F1_array.append(\n",
    "            f1_score(\n",
    "                df[df[\"fitzpatrick\"] == i][\"label\"],\n",
    "                df[df[\"fitzpatrick\"] == i][\"prediction\"],\n",
    "                average=\"weighted\",\n",
    "            )\n",
    "            * 100\n",
    "        )\n",
    "\n",
    "    # PQD\n",
    "    PQD = acc_array.min() / acc_array.max()\n",
    "\n",
    "    # DPM\n",
    "    demo_array = predictions_array / np.sum(predictions_array, axis=1, keepdims=True)\n",
    "    DPM = np.mean(demo_array.min(axis=0) / demo_array.max(axis=0))\n",
    "\n",
    "    # EOM\n",
    "    eo_array = correct_array / labels_array\n",
    "    EOM = np.mean(np.min(eo_array, axis=0) / np.max(eo_array, axis=0))\n",
    "\n",
    "    # NAR\n",
    "    NAR = (acc_array.max() - acc_array.min()) / acc_array.mean()\n",
    "\n",
    "    # AUC\n",
    "    if is_binaryCLF:\n",
    "        # AUC per skin type\n",
    "        AUC = roc_auc_score(df[\"label\"], df[\"prediction_probability\"]) * 100\n",
    "        AUC_per_type = []\n",
    "        for i in range(len(label_array_per_fitz)):\n",
    "            AUC_per_type.append(\n",
    "                roc_auc_score(label_array_per_fitz[i], prob_array[i]) * 100\n",
    "            )\n",
    "        AUC_Gap = max(AUC_per_type) - min(AUC_per_type)\n",
    "    else:\n",
    "        AUC = -1\n",
    "        AUC_per_type = [-1, -1, -1, -1, -1, -1]\n",
    "        AUC_Gap = -1\n",
    "\n",
    "    ##############################          Metrics with binary Sensative attribute         ##############################\n",
    "\n",
    "    correct_array_binary = correct_array_binary[type_indices_binary]\n",
    "    labels_array_binary = labels_array_binary[type_indices_binary]\n",
    "    predictions_array_binary = predictions_array_binary[type_indices_binary]\n",
    "\n",
    "    # avg acc, acc per type\n",
    "    correct_array_sumc_binary, labels_array_sumc_binary = np.sum(\n",
    "        correct_array_binary, axis=1\n",
    "    ), np.sum(\n",
    "        labels_array_binary, axis=1\n",
    "    )  # sum skin conditions\n",
    "    acc_array_binary = correct_array_sumc_binary / labels_array_sumc_binary\n",
    "    avg_acc_binary = (np.sum(correct_array_binary) / np.sum(labels_array_binary)) * 100\n",
    "\n",
    "    # PQD\n",
    "    PQD_binary = acc_array_binary.min() / acc_array_binary.max()\n",
    "\n",
    "    # DPM\n",
    "    demo_array_binary = predictions_array_binary / np.sum(\n",
    "        predictions_array_binary, axis=1, keepdims=True\n",
    "    )\n",
    "    DPM_binary = np.mean(demo_array_binary.min(axis=0) / demo_array_binary.max(axis=0))\n",
    "\n",
    "    # EOM\n",
    "    eo_array_binary = correct_array_binary / labels_array_binary\n",
    "    EOM_binary = np.mean(\n",
    "        np.min(eo_array_binary, axis=0) / np.max(eo_array_binary, axis=0)\n",
    "    )\n",
    "\n",
    "    # getting class-wise TPR, FPR, TNR for fitzpatrick 0\n",
    "    conf_matrix_fitz0 = confusion_matrix(labels_ft0, predictions_ft0)\n",
    "\n",
    "    # Initialize lists to store TPR, TNR, FPR for each class\n",
    "    class_tpr_fitz0 = []\n",
    "    class_tnr_fitz0 = []\n",
    "    class_fpr_fitz0 = []\n",
    "\n",
    "    for i in range(len(conf_matrix_fitz0)):\n",
    "        # Calculate TPR for class i\n",
    "        tpr = conf_matrix_fitz0[i, i] / sum(conf_matrix_fitz0[i, :])\n",
    "        class_tpr_fitz0.append(tpr)\n",
    "\n",
    "        # Calculate TNR for class i\n",
    "        tn = (\n",
    "            sum(sum(conf_matrix_fitz0))\n",
    "            - sum(conf_matrix_fitz0[i, :])\n",
    "            - sum(conf_matrix_fitz0[:, i])\n",
    "            + conf_matrix_fitz0[i, i]\n",
    "        )\n",
    "        fp = sum(conf_matrix_fitz0[:, i]) - conf_matrix_fitz0[i, i]\n",
    "        fn = sum(conf_matrix_fitz0[i, :]) - conf_matrix_fitz0[i, i]\n",
    "        tnr = tn / (tn + fp)\n",
    "        class_tnr_fitz0.append(tnr)\n",
    "\n",
    "        # Calculate FPR for class i\n",
    "        fpr = 1 - tnr\n",
    "        class_fpr_fitz0.append(fpr)\n",
    "\n",
    "    # getting class-wise TPR, FPR, TNR for fitzpatrick 1\n",
    "\n",
    "    conf_matrix_fitz1 = confusion_matrix(labels_ft1, predictions_ft1)\n",
    "\n",
    "    # Initialize lists to store TPR, TNR, FPR for each class\n",
    "    class_tpr_fitz1 = []\n",
    "    class_tnr_fitz1 = []\n",
    "    class_fpr_fitz1 = []\n",
    "\n",
    "    for i in range(len(conf_matrix_fitz1)):\n",
    "        # Calculate TPR for class i\n",
    "        tpr = conf_matrix_fitz1[i, i] / sum(conf_matrix_fitz1[i, :])\n",
    "        class_tpr_fitz1.append(tpr)\n",
    "\n",
    "        # Calculate TNR for class i\n",
    "        tn = (\n",
    "            sum(sum(conf_matrix_fitz1))\n",
    "            - sum(conf_matrix_fitz1[i, :])\n",
    "            - sum(conf_matrix_fitz1[:, i])\n",
    "            + conf_matrix_fitz1[i, i]\n",
    "        )\n",
    "        fp = sum(conf_matrix_fitz1[:, i]) - conf_matrix_fitz1[i, i]\n",
    "        fn = sum(conf_matrix_fitz1[i, :]) - conf_matrix_fitz1[i, i]\n",
    "        tnr = tn / (tn + fp)\n",
    "        class_tnr_fitz1.append(tnr)\n",
    "\n",
    "        # Calculate FPR for class i\n",
    "        fpr = 1 - tnr\n",
    "        class_fpr_fitz1.append(fpr)\n",
    "\n",
    "    # EOpp0\n",
    "    EOpp0 = 0\n",
    "    for c in range(len(class_tnr_fitz0)):\n",
    "        EOpp0 += abs(class_tnr_fitz1[c] - class_tnr_fitz0[c])\n",
    "\n",
    "    # EOpp1\n",
    "    EOpp1 = 0\n",
    "    for c in range(len(class_tpr_fitz0)):\n",
    "        EOpp1 += abs(class_tpr_fitz1[c] - class_tpr_fitz0[c])\n",
    "\n",
    "    # EOdd\n",
    "    EOdd = 0\n",
    "    for c in range(len(class_tpr_fitz0)):\n",
    "        EOdd += abs(\n",
    "            class_tpr_fitz1[c]\n",
    "            - class_tpr_fitz0[c]\n",
    "            + class_fpr_fitz1[c]\n",
    "            - class_fpr_fitz0[c]\n",
    "        )\n",
    "\n",
    "    # NAR\n",
    "    NAR_binary = (\n",
    "        acc_array_binary.max() - acc_array_binary.min()\n",
    "    ) / acc_array_binary.mean()\n",
    "\n",
    "    return {\n",
    "        \"acc_avg\": avg_acc,\n",
    "        \"acc_per_type\": acc_array,\n",
    "        \"acc_gap\": max(acc_array) - min(acc_array),\n",
    "        \"Min_acc\": min(acc_array),\n",
    "        \"F1_score\": F1,\n",
    "        \"F1_per_type\": F1_array,\n",
    "        \"F1_gap\": max(F1_array) - min(F1_array),\n",
    "        \"Min_F1\": min(F1_array),\n",
    "        \"PQD\": PQD,\n",
    "        \"DPM\": DPM,\n",
    "        \"EOM\": EOM,\n",
    "        \"EOpp0\": EOpp0,\n",
    "        \"EOpp1\": EOpp1,\n",
    "        \"EOdd\": EOdd,\n",
    "        \"NAR\": NAR,\n",
    "        \"AUC\": AUC,\n",
    "        \"AUC_per_type\": AUC_per_type,\n",
    "        \"AUC_Gap\": AUC_Gap,\n",
    "        \"AUC_min\": min(AUC_per_type),\n",
    "        \"acc_avg_binary\": avg_acc_binary,\n",
    "        \"acc_per_type_binary\": acc_array_binary,\n",
    "        \"PQD_binary\": PQD_binary,\n",
    "        \"DPM_binary\": DPM_binary,\n",
    "        \"EOM_binary\": EOM_binary,\n",
    "        \"NAR_binary\": NAR_binary,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_avg': 86.16921635966281,\n",
       " 'acc_per_type': array([83.94648829, 84.39869989, 85.90116279, 89.66725044, 90.93851133,\n",
       "        83.33333333]),\n",
       " 'acc_gap': 7.605177993527491,\n",
       " 'Min_acc': 83.33333333333334,\n",
       " 'F1_score': 85.57893397463474,\n",
       " 'F1_per_type': [83.40888098529375,\n",
       "  83.78928603956243,\n",
       "  85.37177898427865,\n",
       "  89.01159924768479,\n",
       "  90.69159774661392,\n",
       "  79.75499454377571],\n",
       " 'F1_gap': 10.936603202838214,\n",
       " 'Min_F1': 79.75499454377571,\n",
       " 'PQD': 0.916370106761566,\n",
       " 'DPM': 0.5278897673948356,\n",
       " 'EOM': 0.6284678839710286,\n",
       " 'EOpp0': 0.09241948268945266,\n",
       " 'EOpp1': 0.13334040160654603,\n",
       " 'EOdd': 0.19503690128792983,\n",
       " 'NAR': 0.08805933919376732,\n",
       " 'AUC': -1,\n",
       " 'AUC_per_type': [-1, -1, -1, -1, -1, -1],\n",
       " 'AUC_Gap': -1,\n",
       " 'AUC_min': -1,\n",
       " 'acc_avg_binary': 86.16921635966281,\n",
       " 'acc_per_type_binary': array([0.84744228, 0.89336016]),\n",
       " 'PQD_binary': 0.9486009323039654,\n",
       " 'DPM_binary': 0.743366066518016,\n",
       " 'EOM_binary': 0.9361077616382222,\n",
       " 'NAR_binary': 0.05275484255800076}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/ali/Outputs/SkinFormer_baseline_3class/validation_results_DiT_S_LRP_level=high_epoch=50_random_holdout.csv')\n",
    "cal_metrics(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_avg': 93.78707461754605,\n",
       " 'acc_per_type': array([93.81270903, 92.30769231, 92.29651163, 96.84763573, 96.76375405,\n",
       "        91.22807018]),\n",
       " 'acc_gap': 5.619565551356516,\n",
       " 'Min_acc': 91.22807017543859,\n",
       " 'F1_score': 93.58431062096106,\n",
       " 'F1_per_type': [93.67097036561044,\n",
       "  92.17603050992126,\n",
       "  91.90241448181142,\n",
       "  96.76754633797887,\n",
       "  96.60765906058379,\n",
       "  89.89139515455304],\n",
       " 'F1_gap': 6.876151183425833,\n",
       " 'Min_F1': 89.89139515455304,\n",
       " 'PQD': 0.9419751911424128,\n",
       " 'DPM': 0.6443480064767824,\n",
       " 'EOM': 0.6964731050522976,\n",
       " 'EOpp0': 0.044660586462973995,\n",
       " 'EOpp1': 0.044660586462973995,\n",
       " 'EOdd': 0.00828135841152311,\n",
       " 'NAR': 0.05986153895383024,\n",
       " 'AUC': 93.51590984421611,\n",
       " 'AUC_per_type': [93.76476145488898,\n",
       "  92.24324621935105,\n",
       "  92.00706736691954,\n",
       "  98.11373092926492,\n",
       "  96.14759805059178,\n",
       "  86.19281045751633],\n",
       " 'AUC_Gap': 11.920920471748587,\n",
       " 'AUC_min': 86.19281045751633,\n",
       " 'acc_avg_binary': 93.78707461754605,\n",
       " 'acc_per_type_binary': array([0.92711634, 0.96177062]),\n",
       " 'PQD_binary': 0.9639682470532304,\n",
       " 'DPM_binary': 0.7845759389942257,\n",
       " 'EOM_binary': 0.9727438513637867,\n",
       " 'NAR_binary': 0.0366928060072583}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/ali/Outputs/SkinFormer_baseline_2class/validation_results_DiT_S_LRP_level=binary_epoch=50_random_holdout.csv')\n",
    "cal_metrics(df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FairDisCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_avg': 86.04433343740243,\n",
       " 'acc_per_type': array([84.11371237, 82.77356446, 86.19186047, 89.31698774, 93.52750809,\n",
       "        85.0877193 ]),\n",
       " 'acc_gap': 10.753943626909575,\n",
       " 'Min_acc': 82.77356446370531,\n",
       " 'F1_score': 85.40178852870271,\n",
       " 'F1_per_type': [83.46605343183822,\n",
       "  82.04096074015393,\n",
       "  85.51682097590682,\n",
       "  88.82539106272448,\n",
       "  93.37276263150967,\n",
       "  82.45370444635752],\n",
       " 'F1_gap': 11.331801891355738,\n",
       " 'Min_F1': 82.04096074015393,\n",
       " 'PQD': 0.8850183882105516,\n",
       " 'DPM': 0.478434030160005,\n",
       " 'EOM': 0.6226869024695112,\n",
       " 'EOpp0': 0.04858410420571213,\n",
       " 'EOpp1': 0.14267129135206158,\n",
       " 'EOdd': 0.10489253203620119,\n",
       " 'NAR': 0.12384310142214475,\n",
       " 'AUC': -1,\n",
       " 'AUC_per_type': [-1, -1, -1, -1, -1, -1],\n",
       " 'AUC_Gap': -1,\n",
       " 'AUC_min': -1,\n",
       " 'acc_avg_binary': 86.04433343740243,\n",
       " 'acc_per_type_binary': array([0.84200996, 0.90140845]),\n",
       " 'PQD_binary': 0.9341047985513806,\n",
       " 'DPM_binary': 0.7766552687660875,\n",
       " 'EOM_binary': 0.9310292841461735,\n",
       " 'NAR_binary': 0.0681402595122808}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/ali/Repos/FairDisCo/results_FairDisCO_50_high_random_holdout.csv')\n",
    "df[\"fitzpatrick\"] = df[\"fitzpatrick\"] -1\n",
    "df[\"fitzpatrick_binary\"] = df['fitzpatrick'].apply(lambda x: 0 if x in [0,1,2] else 1)\n",
    "cal_metrics(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FairPrune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_avg': 81.33000312207305,\n",
       " 'acc_per_type': array([79.43143813, 78.65655471, 82.26744186, 83.71278459, 85.4368932 ,\n",
       "        84.21052632]),\n",
       " 'acc_gap': 6.780338490990744,\n",
       " 'Min_acc': 78.65655471289274,\n",
       " 'F1_score': 78.08004156764137,\n",
       " 'F1_per_type': [76.67339823995785,\n",
       "  74.62891329526849,\n",
       "  79.29608888191215,\n",
       "  80.51718593995612,\n",
       "  82.560866324101,\n",
       "  80.13335158624854],\n",
       " 'F1_gap': 7.93195302883251,\n",
       " 'Min_F1': 74.62891329526849,\n",
       " 'PQD': 0.9206392199349946,\n",
       " 'DPM': 0.49776309188734347,\n",
       " 'EOM': 0.7074291673232631,\n",
       " 'EOpp0': 0.13819241627628487,\n",
       " 'EOpp1': 0.09420496905121217,\n",
       " 'EOdd': 0.23239738532749704,\n",
       " 'NAR': 0.08239972111095889,\n",
       " 'AUC': -1,\n",
       " 'AUC_per_type': [-1, -1, -1, -1, -1, -1],\n",
       " 'AUC_Gap': -1,\n",
       " 'AUC_min': -1,\n",
       " 'acc_avg_binary': 81.33000312207305,\n",
       " 'acc_per_type_binary': array([0.79990946, 0.84305835]),\n",
       " 'PQD_binary': 0.9488186211538607,\n",
       " 'DPM_binary': 0.7022129448437271,\n",
       " 'EOM_binary': 0.9237732879362852,\n",
       " 'NAR_binary': 0.05252554372231485}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/ali/Outputs/FairPrune/validation_results_ResNet18_FairPrune_PIter4_epoch=50_random_holdout.csv\")\n",
    "cal_metrics(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d995bc54c9aaecfe64e6668cd10ce18771211a7298b34b6f0fab6698bea7d7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('skinlesion')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
