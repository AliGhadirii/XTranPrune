seed: 42
root_image_dir: /home/ali/Datasets/PAD-UFES-20/images/
Generated_csv_path: /home/ali/Datasets/PAD-UFES-20/PAD-UFES-20.csv
dataset_name: PAD                 # ["Fitz17k", "HIBA", "PAD"]
output_folder_path: /home/ali/Outputs/PAD-UFES-20/Abblation/Attn/
num_workers: 1
train:
  branch: main                        # ["main", "SA"]
  batch_size: 64
  main_level: high                    # [high, mid, low]
  SA_level: fitzpatrick_binary        # [fitzpatrick_binary, fitzpatrick]
  n_epochs: 100
  pretrained: True                                     # [True, False]
  stratify_cols:
  - high
  - fitzpatrick
  sampler_type: CustomStratified                    # ["WeightedRandom", "Stratified", "CustomStratified"]
eval:
  weight_path: ""
prune:
  main_br_path: /home/ali/Outputs/PAD-UFES-20/XTranPrune_baseline_low/DiT_S_LRP_level=low_checkpoint_BASE.pth
  SA_br_path: /home/ali/Outputs/PAD-UFES-20/XTranPrune_SA_binary/DiT_S_LRP_2SABranch_checkpoint.pth
  stratify_cols:
  - high
  - fitzpatrick
  sampler_type: CustomStratified                    # ["WeightedRandom", "Stratified", "CustomStratified"]
  target_bias_metric: EOM
  bias_metric_prev: 0.562
  max_consecutive_no_improvement: 7
  batch_size: 6
  num_batch_per_iter: 333
  main_mask_retain_rate: 0.8
  pruning_rate: 0.4
  beta1: 0.4
  beta2: 0.4
  cont_method: transformer_attribution                # ["transformer_attribution", "attr", "grad", "attn", "TAM", AttrRoll", "FTaylor", "FTaylorpow2"]
  method: MA_Uncertainty                                          # ['normal', 'MA', 'MA_Uncertainty']
  FObjective: MinJSD_Diff                             # [MinDiff, MinJSD_Diff]
  MaskUpdate_Type: "AND"                              # ["AND", "LAST"]
  apply_pagerank: True                               # [True, False]                 
  edge_type: attention_weights                        # ['attention_weights', 'gradients']
  aggr_type: combined                                 # ['outflow', 'inflow', 'combined']
  PR_alpha: 0.85                                      # parameter Alpha used in the PageRank algorithm
  verbose: 2                                          # [0, 1, 2] (more details as the number grows)
  